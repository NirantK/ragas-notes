{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "414f2aea",
   "metadata": {},
   "source": [
    "- build application\n",
    "- test it manually\n",
    "- use ragas to calculate a score\n",
    "- make an improvement\n",
    "- recompute score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2171b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22507e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext,OpenAIEmbedding\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def build_query_engine(embed_model):\n",
    "    vector_index = VectorStoreIndex.from_documents(\n",
    "        documents, service_context=ServiceContext.from_defaults(chunk_size=512),\n",
    "        embed_model=embed_model,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    query_engine = vector_index.as_query_engine(similarity_top_k=2)\n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf7e41d",
   "metadata": {},
   "source": [
    "# Build an LLM Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9884cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import download_loader\n",
    "\n",
    "SemanticScholarReader = download_loader(\"SemanticScholarReader\")\n",
    "loader = SemanticScholarReader()\n",
    "\n",
    "query_space = \"large language models\"\n",
    "documents = loader.load_data(query=query_space, limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a976abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model = OpenAIEmbedding()\n",
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents, \n",
    "    service_context=ServiceContext.from_defaults(chunk_size=512),\n",
    "    embed_model=openai_model,\n",
    ")\n",
    "vector_index.storage_context.persist(\"openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e3474",
   "metadata": {},
   "source": [
    "# Test it Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!llamachat openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead5970",
   "metadata": {},
   "source": [
    "# Test with Ragas\n",
    "\n",
    "1. Build a test dataset\n",
    "2. Evaluate with Ragas Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d01eb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                   | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|█▏                                                         | 1/50 [00:16<13:30, 16.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|███▌                                                       | 3/50 [00:34<08:29, 10.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|███████                                                    | 6/50 [00:42<04:20,  5.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████████▌                                              | 10/50 [00:52<02:43,  4.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|█████████████████▍                                        | 15/50 [00:58<01:30,  2.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████████████▎                                 | 21/50 [01:04<00:54,  1.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|████████████████████████████████▍                         | 28/50 [01:18<00:42,  1.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|█████████████████████████████████████████▊                | 36/50 [01:42<00:33,  2.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|████████████████████████████████████████████████████▏     | 45/50 [01:52<00:09,  1.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "55it [02:02,  1.52s/it]                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "66it [02:12,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "78it [02:20,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "91it [02:41,  1.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "105it [02:48,  1.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "120it [02:58,  1.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "136it [03:06,  1.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "153it [03:21,  1.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "171it [03:35,  1.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "190it [04:02,  1.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "210it [04:17,  1.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "231it [04:25,  1.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "253it [04:32,  1.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "276it [04:46,  1.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "300it [05:04,  1.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "325it [05:15,  1.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "351it [05:28,  1.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "378it [05:39,  1.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "406it [05:53,  1.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "435it [06:08,  1.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "465it [06:15,  2.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "496it [06:23,  2.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "528it [06:32,  2.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "561it [06:49,  2.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "595it [06:57,  2.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "630it [07:03,  3.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "666it [07:13,  3.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "703it [07:41,  2.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "741it [07:51,  2.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/.pyenv/versions/3.10.12/envs/ragas/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[44], line 5\u001b[0m\n    testset = testsetgenerator.generate(documents, test_size=test_size)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/jjmachan/explodinggradients/ragas/src/ragas/testset/testset_generator.py:311\u001b[0m in \u001b[1;35mgenerate\u001b[0m\n    else [node_idx]\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/jjmachan/explodinggradients/ragas/src/ragas/testset/testset_generator.py:176\u001b[0;36m in \u001b[0;35m_filter_context\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<string>:1\u001b[0;36m\u001b[0m\n\u001b[0;31m    This context is too brief and doesn't provide any explanation or in-depth analysis of the statement. Therefore, it scores low. Score: 2.\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "testsetgenerator = TestsetGenerator.from_default()\n",
    "test_size = 50  # Number of samples to generate\n",
    "testset = testsetgenerator.generate(documents, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81f6e19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_type</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of self-verification in la...</td>\n",
       "      <td>Large Language Models are reasoners with Self-...</td>\n",
       "      <td>The purpose of self-verification in large lang...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the proposed approach for fact-checkin...</td>\n",
       "      <td>- Existing fact-checking approaches either req...</td>\n",
       "      <td>The proposed approach for fact-checking respon...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the proposed method for automatic inst...</td>\n",
       "      <td>- \"We propose Automatic Prompt Engineer (APE) ...</td>\n",
       "      <td>The proposed method for automatic instruction ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the use of large language models for ...</td>\n",
       "      <td>- We prompt the large language model with a se...</td>\n",
       "      <td>The use of large language models for few-shot ...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the performance of the largest fine-tu...</td>\n",
       "      <td>On the MathQA-Python dataset, the largest fine...</td>\n",
       "      <td>The performance of the largest fine-tuned mode...</td>\n",
       "      <td>simple</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the purpose of self-verification in la...   \n",
       "1  What is the proposed approach for fact-checkin...   \n",
       "2  What is the proposed method for automatic inst...   \n",
       "3  How does the use of large language models for ...   \n",
       "4  What is the performance of the largest fine-tu...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Large Language Models are reasoners with Self-...   \n",
       "1  - Existing fact-checking approaches either req...   \n",
       "2  - \"We propose Automatic Prompt Engineer (APE) ...   \n",
       "3  - We prompt the large language model with a se...   \n",
       "4  On the MathQA-Python dataset, the largest fine...   \n",
       "\n",
       "                                              answer question_type  \\\n",
       "0  The purpose of self-verification in large lang...        simple   \n",
       "1  The proposed approach for fact-checking respon...        simple   \n",
       "2  The proposed method for automatic instruction ...        simple   \n",
       "3  The use of large language models for few-shot ...     reasoning   \n",
       "4  The performance of the largest fine-tuned mode...        simple   \n",
       "\n",
       "   episode_done  \n",
       "0          True  \n",
       "1          True  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = testset.to_pandas()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "03012518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b94609c",
   "metadata": {},
   "source": [
    "![](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c83765f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                    | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████████████                                        | 1/3 [01:07<02:14, 67.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|████████████████████████████████████████                    | 2/3 [02:06<01:02, 62.24s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████| 3/3 [02:12<00:00, 44.30s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                    | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████████████                                        | 1/3 [01:07<02:14, 67.19s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|████████████████████████████████████████                    | 2/3 [02:16<01:08, 68.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████| 3/3 [02:17<00:00, 46.00s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# evaluate with ragas\n",
    "from ragas.llama_index import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_precision,\n",
    "    context_recall,\n",
    ")\n",
    "from ragas.llama_index import evaluate\n",
    "\n",
    "metrics = [\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "]\n",
    "\n",
    "test_questions = test_df['question'].values.tolist()\n",
    "test_answers = [[item] for item in test_df['answer'].values.tolist()]\n",
    "\n",
    "result = evaluate(qe1, metrics, test_questions, test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee6a1253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ragas_score': 0.4406, 'context_precision': 0.3372, 'context_recall': 0.6355}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_result = result\n",
    "openai_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "434b227d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of self-verification in la...</td>\n",
       "      <td>[Large Language Models are reasoners with Self...</td>\n",
       "      <td>\\nThe purpose of self-verification in large la...</td>\n",
       "      <td>[The purpose of self-verification in large lan...</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the proposed approach for fact-checkin...</td>\n",
       "      <td>[the fluency and informativeness of its respon...</td>\n",
       "      <td>\\nThe proposed approach for fact-checking resp...</td>\n",
       "      <td>[The proposed approach for fact-checking respo...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the proposed method for automatic inst...</td>\n",
       "      <td>[Automatic Generation of Programming Exercises...</td>\n",
       "      <td>\\nThe proposed method for automatic instructio...</td>\n",
       "      <td>[The proposed method for automatic instruction...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the use of large language models for ...</td>\n",
       "      <td>[TabLLM: Few-shot Classification of Tabular Da...</td>\n",
       "      <td>\\nThe use of large language models for few-sho...</td>\n",
       "      <td>[The use of large language models for few-shot...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the performance of the largest fine-tu...</td>\n",
       "      <td>[Program Synthesis with Large Language Models ...</td>\n",
       "      <td>\\nThe performance of the largest fine-tuned mo...</td>\n",
       "      <td>[The performance of the largest fine-tuned mod...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the purpose of self-verification in la...   \n",
       "1  What is the proposed approach for fact-checkin...   \n",
       "2  What is the proposed method for automatic inst...   \n",
       "3  How does the use of large language models for ...   \n",
       "4  What is the performance of the largest fine-tu...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Large Language Models are reasoners with Self...   \n",
       "1  [the fluency and informativeness of its respon...   \n",
       "2  [Automatic Generation of Programming Exercises...   \n",
       "3  [TabLLM: Few-shot Classification of Tabular Da...   \n",
       "4  [Program Synthesis with Large Language Models ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  \\nThe purpose of self-verification in large la...   \n",
       "1  \\nThe proposed approach for fact-checking resp...   \n",
       "2  \\nThe proposed method for automatic instructio...   \n",
       "3  \\nThe use of large language models for few-sho...   \n",
       "4  \\nThe performance of the largest fine-tuned mo...   \n",
       "\n",
       "                                       ground_truths  context_precision  \\\n",
       "0  [The purpose of self-verification in large lan...           0.312500   \n",
       "1  [The proposed approach for fact-checking respo...           0.400000   \n",
       "2  [The proposed method for automatic instruction...           0.000000   \n",
       "3  [The use of large language models for few-shot...           0.500000   \n",
       "4  [The performance of the largest fine-tuned mod...           0.083333   \n",
       "\n",
       "   context_recall  \n",
       "0        0.666667  \n",
       "1        0.000000  \n",
       "2        0.000000  \n",
       "3        1.000000  \n",
       "4        1.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_result_df = openai_result.to_pandas()\n",
    "openai_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e2fb9",
   "metadata": {},
   "source": [
    "# Make Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4478400a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_precision]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                    | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████████████                                        | 1/3 [01:09<02:19, 69.81s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|████████████████████████████████████████                    | 2/3 [02:01<00:59, 59.19s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████| 3/3 [02:07<00:00, 42.43s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_recall]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                    | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████████████                                        | 1/3 [01:05<02:11, 65.83s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|████████████████████████████████████████                    | 2/3 [02:17<01:09, 69.20s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████| 3/3 [02:19<00:00, 46.47s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "flag_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "query_engine2 = build_query_engine(flag_model)\n",
    "result = evaluate(query_engine2, metrics, test_questions, test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1984d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ragas_score': 0.4392, 'context_precision': 0.3321, 'context_recall': 0.6484}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_result = result\n",
    "hf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8993c674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>answer</th>\n",
       "      <th>ground_truths</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of self-verification in la...</td>\n",
       "      <td>[Large Language Models are reasoners with Self...</td>\n",
       "      <td>\\nThe purpose of self-verification in large la...</td>\n",
       "      <td>[The purpose of self-verification in large lan...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the proposed approach for fact-checkin...</td>\n",
       "      <td>[the fluency and informativeness of its respon...</td>\n",
       "      <td>\\nThe proposed approach for fact-checking resp...</td>\n",
       "      <td>[The proposed approach for fact-checking respo...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the proposed method for automatic inst...</td>\n",
       "      <td>[Automatic Generation of Programming Exercises...</td>\n",
       "      <td>\\nThe proposed method for automatic instructio...</td>\n",
       "      <td>[The proposed method for automatic instruction...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the use of large language models for ...</td>\n",
       "      <td>[TabLLM: Few-shot Classification of Tabular Da...</td>\n",
       "      <td>\\nThe use of large language models for few-sho...</td>\n",
       "      <td>[The use of large language models for few-shot...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the performance of the largest fine-tu...</td>\n",
       "      <td>[Program Synthesis with Large Language Models ...</td>\n",
       "      <td>\\nThe performance of the largest fine-tuned mo...</td>\n",
       "      <td>[The performance of the largest fine-tuned mod...</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the purpose of self-verification in la...   \n",
       "1  What is the proposed approach for fact-checkin...   \n",
       "2  What is the proposed method for automatic inst...   \n",
       "3  How does the use of large language models for ...   \n",
       "4  What is the performance of the largest fine-tu...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Large Language Models are reasoners with Self...   \n",
       "1  [the fluency and informativeness of its respon...   \n",
       "2  [Automatic Generation of Programming Exercises...   \n",
       "3  [TabLLM: Few-shot Classification of Tabular Da...   \n",
       "4  [Program Synthesis with Large Language Models ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  \\nThe purpose of self-verification in large la...   \n",
       "1  \\nThe proposed approach for fact-checking resp...   \n",
       "2  \\nThe proposed method for automatic instructio...   \n",
       "3  \\nThe use of large language models for few-sho...   \n",
       "4  \\nThe performance of the largest fine-tuned mo...   \n",
       "\n",
       "                                       ground_truths  context_precision  \\\n",
       "0  [The purpose of self-verification in large lan...           0.500000   \n",
       "1  [The proposed approach for fact-checking respo...           0.500000   \n",
       "2  [The proposed method for automatic instruction...           0.000000   \n",
       "3  [The use of large language models for few-shot...           0.416667   \n",
       "4  [The performance of the largest fine-tuned mod...           0.083333   \n",
       "\n",
       "   context_recall  \n",
       "0        0.666667  \n",
       "1        0.000000  \n",
       "2        0.000000  \n",
       "3        1.000000  \n",
       "4        1.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_result_df = hf_result.to_pandas()\n",
    "hf_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0005a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "5     0.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     0.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    0.0\n",
       "13    0.0\n",
       "14    0.0\n",
       "15    0.0\n",
       "16    0.0\n",
       "17    0.0\n",
       "18    0.0\n",
       "19    0.0\n",
       "20    0.0\n",
       "21    0.0\n",
       "22    0.0\n",
       "23    0.0\n",
       "24    0.0\n",
       "25    0.0\n",
       "26    0.0\n",
       "27    0.0\n",
       "28    0.4\n",
       "29    0.0\n",
       "30    0.0\n",
       "Name: context_recall, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_result_df[\"context_recall\"] - openai_result_df[\"context_recall\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13e3b60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question             In what ways can language models enhance robot...\n",
       "contexts             [ProgPrompt: Generating Situated Robot Task Pl...\n",
       "answer               \\nLanguage models can enhance robot task plann...\n",
       "ground_truths        [Language models can enhance robot task planni...\n",
       "context_precision                                                  0.5\n",
       "context_recall                                                     1.0\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_result_df.iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c5202a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question             In what ways can language models enhance robot...\n",
       "contexts             [ProgPrompt: Generating Situated Robot Task Pl...\n",
       "answer               \\nLanguage models can enhance robot task plann...\n",
       "ground_truths        [Language models can enhance robot task planni...\n",
       "context_precision                                             0.285714\n",
       "context_recall                                                0.333333\n",
       "Name: 6, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_result_df.iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ecfd98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
