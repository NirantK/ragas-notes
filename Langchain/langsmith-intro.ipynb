{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d9c713",
   "metadata": {},
   "source": [
    "# Langsmith\n",
    "**The companion tool I've been waiting for**\n",
    "![viusalize your runs with langsmith](https://docs.smith.langchain.com/assets/images/run_details-f579aef109cb8f576e7a4a864e405143.png)\n",
    "\n",
    "debugging is a pain when building complicated LLM application. There is a lot of text to parse from each step, each input and output is different and if there is an a step mid-way, it is hard to change just that value and run it again. Basically when developing I want a tool that\n",
    "- shows me exactly what the input/outputs are from the LLM, tools etc (visualisation)\n",
    "- allows me to edit prompts at each step and see how it affects the output (live debugging)\n",
    "- show the exact sequence of events, the time taken at each step, tokens used\n",
    "- share the my debug traces with other (honestly I didn't know I needed this until I saw langsmith has support for it ðŸ˜‚)\n",
    "\n",
    "and boy does langsmith solve these problems. In-face I've changed my workflow to always have langsmith open in the side, logging everything, ready to be help me visualize what is happening with my apps.\n",
    "\n",
    "Langsmith also has a few more features and you can see the whole list [here](https://docs.smith.langchain.com/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43ec44",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296878ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=\"<your-api-key>\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"<your-project>\"  # if not specified, defaults to \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d70977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.predict(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6bddf0",
   "metadata": {},
   "source": [
    "and this is the output of the run in langsmith's dashboard\n",
    "\n",
    "![](imgs/smith-getstarted.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2988c6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
