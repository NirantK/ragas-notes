{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf5aba9",
   "metadata": {},
   "source": [
    "## Query Response Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d1e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import openai\n",
    "from llama_index.evaluation.relevancy import DEFAULT_EVAL_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae264c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = json.load(open(\"/Users/shahules/openai-key.json\"))[\n",
    "    \"ikka\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bcaef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "680306da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm2(prompt, **kwargs):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=kwargs.get(\"model\", \"gpt-4\"),\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "        temperature=kwargs.get(\"temperature\", 0),\n",
    "        top_p=kwargs.get(\"top_p\", 1),\n",
    "        frequency_penalty=kwargs.get(\"frequency_penalty\", 0.0),\n",
    "        presence_penalty=kwargs.get(\"presence_penalty\", 0.0),\n",
    "        max_tokens=kwargs.get(\"max_tokens\", 500),\n",
    "        n=kwargs.get(\"n\", 1),\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c5716",
   "metadata": {},
   "source": [
    "## Failure case: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b0cd3",
   "metadata": {},
   "source": [
    "- Here I am giving:\n",
    "1. A simple query\n",
    "2. Context containing information that can answer the query but information is broken down in two nodes\n",
    "3. A response which is **partially incorrect**\n",
    "\n",
    "I am using same mechanism and prompts from llama_index used in QueryResponseEvalutor which is used by Albus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f58fa363",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When and where was Einstein born?\"\n",
    "contexts = [\"Albert Einstein was a German-born theoretical physicist, widely held to be one of the greatest and most influential scientists of all time.\",\n",
    "           \"He was born on 14 March 1879.\"]\n",
    "response = \"Einstein was born in Germany on 15 April 1879.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f23584a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response = f\"Question: {query}\\nResponse: {response}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d93a2fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL VERDICT\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "for ctx in contexts:\n",
    "    prompt = DEFAULT_EVAL_TEMPLATE.template.format(query_str=query_response,context_str=ctx)\n",
    "#     print(prompt)\n",
    "    output = llm2(prompt)['choices'][0]['message']['content']\n",
    "#     print(output)\n",
    "#     print(\"---\")\n",
    "    answer.append(output)\n",
    "print(\"FINAL VERDICT\")\n",
    "print(\"YES\" in answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b6379",
   "metadata": {},
   "source": [
    "- You can see that this check fails to ensure the total consistency with the context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2462d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas",
   "language": "python",
   "name": "ragas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
